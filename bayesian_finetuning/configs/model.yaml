# python bayesian_finetuning/bin/train.py --config bayesian_finetuning/configs/model.yaml

wandb_project_name: 'bayesian_finetuning'

training:
  default_root_dir: '.'
  log_every_n_steps: 10
  val_check_interval: 800
  limit_val_batches: 50
  gpus: 0 #1
  accumulate_grad_batches: 1
  max_epochs: 100
  deterministic: True
  data_workers: 4
  train_batch_size: 16
  eval_batch_size: 16

prediction:
  model_path: ''

hparams:
  model_name_or_path: prajjwal1/bert-tiny
  task_name: rte
  seed: 1234
  dropout: 0.1
  learning_rate: 2e-5
  precision: 32

